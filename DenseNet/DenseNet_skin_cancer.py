# -*- coding: utf-8 -*-
"""DenseNet_Skin_cancer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OADUVzgs8lAKBwOYLzQlaUgr-xRejLn9
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report, confusion_matrix

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

# Load metadata and image paths
df = pd.read_csv("/content/drive/MyDrive/archive (2).zip (Unzipped Files)/HAM10000_metadata.csv")
df_meta = df.rename(columns={'dx': 'label'})
folder1 = "/content/drive/MyDrive/archive (2).zip (Unzipped Files)/HAM10000_images_part_1"
folder2 = "/content/drive/MyDrive/archive (2).zip (Unzipped Files)/HAM10000_images_part_2"

# List all .jpg files from both folders
images1 = [os.path.join(folder1, fname) for fname in os.listdir(folder1) if fname.endswith(".jpg")]
images2 = [os.path.join(folder2, fname) for fname in os.listdir(folder2) if fname.endswith(".jpg")]
all_images = images1 + images2

# Create image path DataFrame
df_images = pd.DataFrame({'image_path': all_images})
df_images['image_id'] = df_images['image_path'].apply(lambda x: os.path.basename(x).replace('.jpg', ''))

df = pd.merge(df_meta, df_images, on='image_id', how='inner')

le = LabelEncoder()
df['label_encoded'] = le.fit_transform(df['label'])

# Split into training and test sets
train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label_encoded'], random_state=42)
train_df['label_encoded'] = train_df['label_encoded'].astype(str)
test_df['label_encoded'] = test_df['label_encoded'].astype(str)

# Compute class weights
class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(train_df['label_encoded'].astype(int)),
    y=train_df['label_encoded'].astype(int)
)
class_weights = dict(enumerate(class_weights))

# Create ImageDataGenerators
img_size = (224, 224)
batch_size = 32

train_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, zoom_range=0.2)
test_gen = ImageDataGenerator(rescale=1./255)

train_data = train_gen.flow_from_dataframe(
    train_df,
    x_col='image_path',
    y_col='label_encoded',
    target_size=img_size,
    class_mode='sparse',
    batch_size=batch_size
)

test_data = test_gen.flow_from_dataframe(
    test_df,
    x_col='image_path',
    y_col='label_encoded',
    target_size=img_size,
    class_mode='sparse',
    batch_size=batch_size,
    shuffle=False
)

# Build DenseNet121 model
base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
base_model.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.3)(x)
output = Dense(len(le.classes_), activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train initial model
history = model.fit(
    train_data,
    validation_data=test_data,
    epochs=5,
    class_weight=class_weights
)

# Fine-tune entire DenseNet
base_model.trainable = True
model.compile(optimizer=Adam(1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

history_finetune = model.fit(
    train_data,
    validation_data=test_data,
    epochs=5,
    class_weight=class_weights
)

# Evaluate on test data
test_loss, test_acc = model.evaluate(test_data)
print(f"Final Test Accuracy (Fine-Tuned): {test_acc:.4f}")

# Predictions
y_true = test_data.classes
y_probs = model.predict(test_data)
y_pred = np.argmax(y_probs, axis=1)

class_labels = df['label'].unique()
print(class_labels)

# Classification Report
print("Classification Report:")
print(classification_report(y_true, y_pred, target_names=class_labels))

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix (DenseNet121 Fine-Tuned)")
plt.show()

# Accuracy and Loss Graphs
plt.figure(figsize=(12, 5))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Acc (Initial)')
plt.plot(history.history['val_accuracy'], label='Val Acc (Initial)')
plt.plot(range(len(history_finetune.history['accuracy'])), history_finetune.history['accuracy'], label='Train Acc (Fine-Tune)')
plt.plot(range(len(history_finetune.history['val_accuracy'])), history_finetune.history['val_accuracy'], label='Val Acc (Fine-Tune)')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss (Initial)')
plt.plot(history.history['val_loss'], label='Val Loss (Initial)')
plt.plot(range(len(history_finetune.history['loss'])), history_finetune.history['loss'], label='Train Loss (Fine-Tune)')
plt.plot(range(len(history_finetune.history['val_loss'])), history_finetune.history['val_loss'], label='Val Loss (Fine-Tune)')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()